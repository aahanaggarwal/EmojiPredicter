{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emoji predicter",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dltnWgyYUacn",
        "outputId": "ae6bcb2f-888e-4945-b1af-850903a45bce"
      },
      "source": [
        "# Author: Robert Guthrie\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fcff671a9b0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgMhv7e_Uitu",
        "outputId": "268d8bba-d23d-456c-8a26-4af804921e41"
      },
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "\n",
        "training_data = [\n",
        "    # Tags are: DET - determiner; NN - noun; V - verb\n",
        "    # For example, the word \"The\" is a determiner\n",
        "    (\"no object is so beautiful that under certain conditions it will not look ugly oscar wilde rt …\".split(), \":red_heart:\"),\n",
        "    (\"asahd really is a grown man in the body of a 1 year old\".split(), \":face_with_tears_of_joy:\"),\n",
        "    (\"yoongi tweet hello im min fell on butt what the min\".split(), \":face_with_tears_of_joy:\"),\n",
        "    (\"will and jada on how they discipline their children\".split(), \":clapping_hands:\")\n",
        "]\n",
        "word_to_ix = {}\n",
        "# For each words-list (sentence) and tags-list in each tuple of training_data\n",
        "for sent, tags in training_data:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix:  # word has not been assigned an index yet\n",
        "            word_to_ix[word] = len(word_to_ix)  # Assign each word with a unique index\n",
        "print(word_to_ix)\n",
        "tag_to_ix = {\":red_heart:\": 0, \":face_with_tears_of_joy:\": 1, \":clapping_hands:\": 2}  # Assign each tag with a unique index\n",
        "\n",
        "emojis = tag_to_ix.keys()\n",
        "\n",
        "# These will usually be more like 32 or 64 dimensional.\n",
        "# We will keep them small, so we can see how the weights change as we train.\n",
        "EMBEDDING_DIM = 6\n",
        "HIDDEN_DIM = 6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'no': 0, 'object': 1, 'is': 2, 'so': 3, 'beautiful': 4, 'that': 5, 'under': 6, 'certain': 7, 'conditions': 8, 'it': 9, 'will': 10, 'not': 11, 'look': 12, 'ugly': 13, 'oscar': 14, 'wilde': 15, 'rt': 16, '…': 17, 'asahd': 18, 'really': 19, 'a': 20, 'grown': 21, 'man': 22, 'in': 23, 'the': 24, 'body': 25, 'of': 26, '1': 27, 'year': 28, 'old': 29, 'yoongi': 30, 'tweet': 31, 'hello': 32, 'im': 33, 'min': 34, 'fell': 35, 'on': 36, 'butt': 37, 'what': 38, 'and': 39, 'jada': 40, 'how': 41, 'they': 42, 'discipline': 43, 'their': 44, 'children': 45}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3G02__1UuYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3077f97f-c9a2-43ff-f4d7-8a1b04f817d5"
      },
      "source": [
        "emojis_tensor = prepare_sequence(emojis, tag_to_ix)\n",
        "emoji_embeddings = nn.Embedding(len(emojis), EMBEDDING_DIM)\n",
        "\n",
        "emoji_embeds = emoji_embeddings(emojis_tensor)\n",
        "\n",
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.emojis = prepare_sequence(emojis, tag_to_ix)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim*2, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores\n",
        "\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# See what the scores are before training\n",
        "# Note that element i,j of the output is the score for tag j for word i.\n",
        "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    tag_scores = model(inputs)\n",
        "    print(tag_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.2256, -1.1444, -0.9467],\n",
            "        [-1.0909, -1.1137, -1.0915],\n",
            "        [-1.0793, -1.0959, -1.1211],\n",
            "        [-1.1501, -1.1245, -1.0256],\n",
            "        [-1.0497, -1.1142, -1.1339],\n",
            "        [-1.1073, -1.1159, -1.0731],\n",
            "        [-1.1279, -1.0934, -1.0752],\n",
            "        [-1.1062, -1.0657, -1.1249],\n",
            "        [-1.0460, -1.0454, -1.2136],\n",
            "        [-1.0064, -1.0914, -1.2083],\n",
            "        [-1.0241, -1.0949, -1.1832],\n",
            "        [-1.0855, -1.1260, -1.0849],\n",
            "        [-0.9959, -1.2458, -1.0703],\n",
            "        [-1.1488, -1.1974, -0.9649],\n",
            "        [-1.1161, -1.1826, -1.0052],\n",
            "        [-1.1146, -1.1546, -1.0307],\n",
            "        [-1.0780, -1.2106, -1.0169],\n",
            "        [-1.0023, -1.0824, -1.2236]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciJ-O6vbagQn"
      },
      "source": [
        "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "    for sentence, tags in training_data:\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "        # Tensors of word indices.\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = prepare_sequence([tags]*len(sentence), tag_to_ix)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        tag_scores = model(sentence_in)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        #  calling optimizer.step()\n",
        "        loss = loss_function(tag_scores, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# See what the scores are after training\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ12ek-Cz-2E",
        "outputId": "d0eb5263-7d97-46fd-da11-1c2816eaa68d"
      },
      "source": [
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(\"will and jada fell butt min\".split(\" \"), word_to_ix)\n",
        "    tag_scores = model(inputs)\n",
        "    \n",
        "    scores = torch.argmax(tag_scores, dim=1)\n",
        "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
        "    # for word i. The predicted tag is the maximum scoring tag.\n",
        "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
        "    # since 0 is index of the maximum value of row 1,\n",
        "    # 1 is the index of maximum value of row 2, etc.\n",
        "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
        "    print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1])\n"
          ]
        }
      ]
    }
  ]
}